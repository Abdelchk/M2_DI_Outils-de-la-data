# Exercice 03 : ELK Stack (Elasticsearch, Logstash, Kibana) - Analyse de logs

## ğŸ¯ Objectifs

- Installer et configurer l'ELK Stack
- IngÃ©rer des donnÃ©es avec Logstash
- Indexer dans Elasticsearch
- Visualiser dans Kibana
- MaÃ®triser un stack d'analyse de donnÃ©es complet

## ğŸ“‹ PrÃ©requis

- Docker et Docker Compose
- 4GB RAM minimum
- Connaissances de base en JSON

## ğŸ“¦ Installation

### Avec Docker Compose (RecommandÃ©)

CrÃ©ez un fichier `docker-compose.yml` :

```yaml
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    ports:
      - "5044:5044"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

volumes:
  es_data:
```

Lancez avec :
```bash
docker-compose up -d
```

## ğŸ“Š DonnÃ©es

1. **GÃ©nÃ©rez des logs simulÃ©s** :
   ```bash
   cd exercice-03
   python generer_logs.py
   ```

## ğŸ“ Instructions

### Ã‰tape 1 : Configuration Logstash

CrÃ©ez un fichier `logstash.conf` :

```ruby
input {
  file {
    path => "/usr/share/logstash/data/logs/*.log"
    start_position => "beginning"
    codec => "json"
  }
}

filter {
  date {
    match => [ "timestamp", "ISO8601" ]
  }
  
  mutate {
    convert => {
      "status_code" => "integer"
      "response_time" => "float"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
}
```

### Ã‰tape 2 : VÃ©rifier Elasticsearch

1. **VÃ©rifiez qu'Elasticsearch fonctionne** :
   ```bash
   curl http://localhost:9200
   ```

2. **VÃ©rifiez les indices crÃ©Ã©s** :
   ```bash
   curl http://localhost:9200/_cat/indices?v
   ```

### Ã‰tape 3 : Configuration Kibana

1. **AccÃ©dez Ã  Kibana** : http://localhost:5601
2. **Configurez l'index pattern** :
   - Allez dans Stack Management > Index Patterns
   - CrÃ©ez un pattern : `logs-*`
   - SÃ©lectionnez `@timestamp` comme time field

### Ã‰tape 4 : CrÃ©er des visualisations dans Kibana

CrÃ©ez au moins 5 visualisations :

1. **Line Chart** : Nombre de requÃªtes par heure
   - Metric : Count
   - Bucket : Date Histogram sur `@timestamp`

2. **Pie Chart** : RÃ©partition par status code
   - Slice : Terms sur `status_code`

3. **Bar Chart** : Top 10 endpoints
   - X-axis : Terms sur `endpoint`
   - Y-axis : Count

4. **Metric** : Temps de rÃ©ponse moyen
   - Metric : Average de `response_time`

5. **Data Table** : RequÃªtes avec erreurs (status >= 400)
   - Filtre : `status_code >= 400`
   - Colonnes : timestamp, endpoint, status_code, response_time

### Ã‰tape 5 : CrÃ©er un Dashboard

1. **CrÃ©ez un dashboard** : "Monitoring Application"
2. **Ajoutez vos visualisations**
3. **Configurez les filtres** :
   - Filtre temporel
   - Filtre par status code
   - Filtre par endpoint

### Ã‰tape 6 : RequÃªtes Elasticsearch

Testez des requÃªtes dans Dev Tools :

1. **Recherche simple** :
```json
GET /logs-*/_search
{
  "query": {
    "match": {
      "endpoint": "/api/users"
    }
  }
}
```

2. **AgrÃ©gation** :
```json
GET /logs-*/_search
{
  "size": 0,
  "aggs": {
    "status_codes": {
      "terms": {
        "field": "status_code"
      }
    }
  }
}
```

## ğŸ“ Structure attendue

```
exercice-03/
â”œâ”€â”€ README.md (ce fichier)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ logstash.conf
â”œâ”€â”€ generer_logs.py
â”œâ”€â”€ donnees/
â”‚   â””â”€â”€ logs/ (fichiers de logs)
â””â”€â”€ solutions/
    â””â”€â”€ votre-nom/
        â”œâ”€â”€ screenshots/
        â”œâ”€â”€ dashboard_export.json
        â”œâ”€â”€ resultats.md
        â””â”€â”€ requetes_elasticsearch.md
```

## âœ… CritÃ¨res d'Ã©valuation

- [ ] ELK Stack installÃ© et fonctionnel
- [ ] Logstash ingÃ¨re les donnÃ©es
- [ ] Elasticsearch indexe correctement
- [ ] Au moins 5 visualisations crÃ©Ã©es dans Kibana
- [ ] Dashboard fonctionnel
- [ ] Documentation complÃ¨te

## ğŸ’¡ Conseils

- Commencez avec peu de donnÃ©es pour tester
- Utilisez Dev Tools pour tester les requÃªtes
- Explorez les diffÃ©rents types de visualisations
- Utilisez les filtres pour affiner vos analyses
- Documentez vos requÃªtes Elasticsearch

## ğŸ“š Ressources

- Documentation ELK : https://www.elastic.co/guide/
- Guide Kibana : https://www.elastic.co/guide/en/kibana/current/index.html
- Guide Logstash : https://www.elastic.co/guide/en/logstash/current/index.html

## ğŸ†˜ Aide

Si vous Ãªtes bloquÃ© :
1. VÃ©rifiez les logs des containers Docker
2. Consultez la documentation officielle
3. Ouvrez une issue sur le dÃ©pÃ´t GitHub

## ğŸ“¤ Comment soumettre votre solution

### Ã‰tapes pour pousser votre exercice sur GitHub

1. **GÃ©nÃ©rez les logs** :
   ```bash
   cd exercice-03
   python generer_logs.py
   ```

2. **CrÃ©ez votre dossier de solution** :
   ```bash
   mkdir -p solutions/votre-nom
   cd solutions/votre-nom
   ```

3. **Exportez votre dashboard** depuis Kibana
4. **Prenez des captures d'Ã©cran**
5. **CrÃ©ez un fichier `resultats.md`**

6. **Ajoutez et commitez** :
   ```bash
   git add solutions/votre-nom/
   git commit -m "Solution exercice 03 - Votre Nom"
   git push origin main
   ```

**Important** : N'oubliez pas de remplacer "votre-nom" par votre vrai nom !
