# Exercice 03 : Pipeline ETL avec Python

## ğŸ¯ Objectifs

- Comprendre le concept de pipeline ETL (Extract, Transform, Load)
- ImplÃ©menter un pipeline complet de traitement de donnÃ©es
- GÃ©rer les erreurs et la validation des donnÃ©es
- Optimiser les performances du pipeline

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- BibliothÃ¨ques : pandas, requests, sqlalchemy
- Connaissances en programmation orientÃ©e objet

## ğŸ“¦ Installation

```bash
pip install pandas requests sqlalchemy
```

## ğŸ“ Instructions

### Contexte

Vous devez crÃ©er un pipeline ETL qui :
1. **Extract** : RÃ©cupÃ¨re des donnÃ©es depuis plusieurs sources (API, fichiers CSV, base de donnÃ©es)
2. **Transform** : Nettoie, transforme et enrichit les donnÃ©es
3. **Load** : Charge les donnÃ©es transformÃ©es dans une destination finale

### Ã‰tape 1 : Architecture du pipeline

1. CrÃ©ez une structure de classes pour votre pipeline :
   - `Extractor` : Classe abstraite pour l'extraction
   - `Transformer` : Classe pour les transformations
   - `Loader` : Classe abstraite pour le chargement
   - `ETLPipeline` : Classe principale qui orchestre le tout

2. ImplÃ©mentez le pattern Strategy pour permettre diffÃ©rents types d'extracteurs et loaders

### Ã‰tape 2 : Extraction (Extract)

CrÃ©ez plusieurs extracteurs :

1. **CSVExtractor** : Lit des donnÃ©es depuis un fichier CSV
2. **APIExtractor** : RÃ©cupÃ¨re des donnÃ©es depuis une API REST
3. **DatabaseExtractor** : Extrait des donnÃ©es depuis une base de donnÃ©es SQLite

### Ã‰tape 3 : Transformation (Transform)

ImplÃ©mentez les transformations suivantes :

1. **Nettoyage** :
   - Suppression des doublons
   - Gestion des valeurs manquantes
   - Normalisation des formats (dates, nombres, textes)

2. **Enrichissement** :
   - Ajout de colonnes calculÃ©es
   - Jointures avec des donnÃ©es de rÃ©fÃ©rence
   - Calculs statistiques

3. **Validation** :
   - VÃ©rification des types de donnÃ©es
   - Validation des contraintes mÃ©tier
   - DÃ©tection d'anomalies

4. **AgrÃ©gation** :
   - Regroupements par catÃ©gories
   - Calculs de mÃ©triques agrÃ©gÃ©es

### Ã‰tape 4 : Chargement (Load)

CrÃ©ez plusieurs loaders :

1. **CSVLoader** : Sauvegarde dans un fichier CSV
2. **DatabaseLoader** : Charge dans une base de donnÃ©es SQLite
3. **JSONLoader** : Exporte en format JSON

### Ã‰tape 5 : Orchestration

1. CrÃ©ez la classe `ETLPipeline` qui :
   - Configure les extracteurs, transformers et loaders
   - ExÃ©cute le pipeline Ã©tape par Ã©tape
   - GÃ¨re les erreurs et les logs
   - Fournit des mÃ©triques d'exÃ©cution

2. ImplÃ©mentez un systÃ¨me de logging pour tracer l'exÃ©cution

3. Ajoutez la gestion des erreurs avec retry logic

### Ã‰tape 6 : Tests et validation

1. CrÃ©ez des tests unitaires pour chaque composant
2. Testez le pipeline complet avec des donnÃ©es rÃ©elles
3. Mesurez les performances (temps d'exÃ©cution, mÃ©moire)
4. Documentez les rÃ©sultats

## ğŸ“ Structure attendue

```
exercice-03/
â”œâ”€â”€ README.md (ce fichier)
â”œâ”€â”€ donnees/
â”‚   â”œâ”€â”€ source1.csv
â”‚   â”œâ”€â”€ source2.csv
â”‚   â””â”€â”€ reference_data.json
â”œâ”€â”€ solutions/
â”‚   â””â”€â”€ votre-nom/
â”‚       â”œâ”€â”€ pipeline/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ extractors.py
â”‚       â”‚   â”œâ”€â”€ transformers.py
â”‚       â”‚   â”œâ”€â”€ loaders.py
â”‚       â”‚   â””â”€â”€ pipeline.py
â”‚       â”œâ”€â”€ tests/
â”‚       â”‚   â””â”€â”€ test_pipeline.py
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ resultats.md
â”‚       â””â”€â”€ logs/
```

## âœ… CritÃ¨res d'Ã©valuation

- [ ] Architecture propre et modulaire
- [ ] Code respectant les principes SOLID
- [ ] Gestion d'erreurs robuste
- [ ] Logging complet
- [ ] Tests unitaires prÃ©sents
- [ ] Documentation claire
- [ ] Pipeline fonctionnel end-to-end

## ğŸ’¡ Conseils

- Utilisez des classes abstraites (ABC) pour dÃ©finir les interfaces
- ImplÃ©mentez le pattern Strategy pour la flexibilitÃ©
- Utilisez le module `logging` pour les logs
- Pensez Ã  la performance : utilisez des gÃ©nÃ©rateurs pour les gros volumes
- Documentez chaque classe et mÃ©thode

## ğŸš€ Niveau avancÃ© (Bonus)

- Ajoutez un systÃ¨me de parallÃ©lisation (multiprocessing)
- ImplÃ©mentez un systÃ¨me de cache pour Ã©viter les re-extractions
- CrÃ©ez un dashboard de monitoring du pipeline
- Ajoutez la validation de schÃ©ma avec Pydantic

## ğŸ“¤ Comment soumettre votre solution

### Ã‰tapes pour pousser votre exercice sur GitHub

1. **PrÃ©parez votre environnement** :
   ```bash
   cd exercice-03
   ```
   
   2. **Installez les dÃ©pendances** :
   ```bash
   # Installez les outils requis selon les instructions du README
   ```

2. **CrÃ©ez votre dossier de solution** :
   ```bash
   mkdir -p solutions/votre-nom
   cd solutions/votre-nom
   ```

3. **Placez tous vos fichiers** dans ce dossier :
   - Votre code source
   - Votre fichier `resultats.md`
   - Tous les fichiers gÃ©nÃ©rÃ©s (graphiques, exports, etc.)

4. **Ajoutez et commitez vos fichiers** :
   ```bash
   git add solutions/votre-nom/
   git commit -m "Solution exercice 03 - Votre Nom"
   ```

5. **Poussez vers GitHub** :
   ```bash
   git push origin main
   ```
   
   Si vous avez forkÃ© le dÃ©pÃ´t :
   ```bash
   git push origin votre-branche
   ```

6. **CrÃ©ez une Pull Request** (si vous avez forkÃ©) ou vos fichiers seront directement visibles dans le dÃ©pÃ´t principal.

### Structure de votre soumission

Votre dossier `solutions/votre-nom/` doit contenir :
- âœ… Tous vos fichiers de code source
- âœ… `resultats.md` : Votre analyse et rÃ©sultats
- âœ… Tous les fichiers gÃ©nÃ©rÃ©s (graphiques, exports, etc.)
- âœ… Un fichier `README.md` (optionnel) expliquant votre approche

### VÃ©rification

Avant de pousser, vÃ©rifiez que :
- [ ] Votre code fonctionne sans erreur
- [ ] Tous les fichiers sont prÃ©sents
- [ ] La documentation est complÃ¨te
- [ ] Les critÃ¨res d'Ã©valuation sont remplis

**Important** : N'oubliez pas de remplacer "votre-nom" par votre vrai nom dans le chemin du dossier ! dans le README principal du dÃ©pÃ´t pour soumettre votre solution.

